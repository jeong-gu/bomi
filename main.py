from datetime import datetime
import pickle
from typing import Optional
from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv
import os
import openai
import logging
from sqlalchemy import and_, create_engine, or_
from sqlalchemy.orm import sessionmaker, Session
from scipy.special import softmax 
from models import Base, User, UserRole, Caregiver, UserPreference,Parent,Review
from passlib.context import CryptContext
from fastapi.responses import JSONResponse
from typing import Optional, Dict, List
from sentence_transformers import SentenceTransformer
import numpy as np

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OpenAI API ì„¤ì •
from openai import OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
chat_model = "gpt-4o"

DATABASE_URL = "sqlite:///./users.db"
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base.metadata.create_all(bind=engine)

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# ë¦¬ë·° API URL (Streamlit ìª½ì—ì„œ ì‚¬ìš©)
REVIEW_API_URL = "http://localhost:8005/reviews"

class QueryRequest(BaseModel):
    prompt: str

class ConditionInfo(BaseModel):
    days: List[str]
    times: List[Dict[str, int]]
    special: bool
    age_min: float
    age_max: float
    
class RegisterRequest(BaseModel):
    username: str
    email: str
    password: str
    role: UserRole
    age: int
    phone: str
    #answers: Optional[list[str]] = None

    conditions: Optional[ConditionInfo] = None
    
    service_type: Optional[int] = None
    hours: Optional[float] = None
    children_count: Optional[int] = None
    income_type: Optional[int] = None
    is_night: Optional[bool] = False
    is_holiday: Optional[bool] = False
    is_multi_child: Optional[int] = 0


class LoginRequest(BaseModel):
    email: str
    password: str

class PreferenceRequest(BaseModel):
    email: str
    summary: str

class ChatPreferenceRequest(BaseModel):
    email: str
    history: list[str]

class RecommendationRequest(BaseModel):
    email: str

class ReviewCreate(BaseModel):
    caregiver_id: int
    parent_name:  str
    content:      str

class ReviewRead(BaseModel):
    id:           int
    caregiver_id: int
    parent_name:  str
    content:      str
    timestamp:    datetime
    
    class Config:
        orm_mode = True

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

caregiver_questions = [
    "ì•„ì´ì™€ì˜ ê°ˆë“± ìƒí™©ì—ì„œ, ì•„ì´ì˜ ë§ˆìŒì„ ì–´ë–»ê²Œ ì´í•´í•˜ë ¤ í•˜ì‹œë‚˜ìš”?",
    "ì•„ì´ì—ê²Œ ë‹¨í˜¸í•˜ê²Œ í›ˆìœ¡í•´ì•¼ í•  ìƒí™©ì´ ì˜¨ë‹¤ë©´, ë³´í†µ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ì‹œë‚˜ìš”?",
    "í•˜ë£¨ ì¤‘ ì•„ì´ì™€ í•¨ê»˜í•˜ëŠ” ë£¨í‹´ì´ë‚˜ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ìƒí™œ ìŠµê´€ì´ ìˆìœ¼ì‹ ê°€ìš”?",
    "ì•„ì´ì™€ í•¨ê»˜í•˜ë©´ì„œ ê°€ì¥ ì¦ê±°ì› ë˜ ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
    "ì˜ˆìƒì¹˜ ëª»í•œ ëŒë°œ ìƒí™©(ì˜ˆ: ì•„ì´ê°€ ê°‘ìê¸° ì•„í”Œ ë•Œ)ì´ ìƒê¸°ë©´, ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì˜¤ì…¨ë‚˜ìš”?",
    "ì•„ì´ë¥¼ ëŒë´ì£¼ì‹œëŠ” ë¶„ì—ê²Œ ê°€ì¥ ë°”ë¼ëŠ” â€˜ë§ˆìŒê°€ì§â€™ì€ ì–´ë–¤ ëª¨ìŠµì¼ê¹Œìš”?",
    "ì•„ì´ì™€ ê´€ê³„ë¥¼ ë§ºëŠ” ë° ìˆì–´ ì¤‘ìš”í•˜ë‹¤ê³  ëŠë¼ëŠ” íƒœë„ë‚˜ ìì„¸ê°€ ìˆë‹¤ë©´ìš”?",
    "ëŒë´„ì€ í•œë‘ ë²ˆë³´ë‹¤ ê¾¸ì¤€í•¨ì´ ì¤‘ìš”í•˜ë‹¤ê³  í•˜ì–ì•„ìš”, ì†Œì¤‘í•˜ê²Œ ìƒê°í•˜ëŠ” â€˜ê¾¸ì¤€í•¨â€™ì´ ìˆë‹¤ë©´ ì–´ë–¤ ê±¸ê¹Œìš”?",
    "ì•„ì´ë¥¼ ëŒë³´ëŠ” ê³¼ì •ì—ì„œ ê°€ì¡±ë¼ë¦¬ ë‚˜ëˆ„ëŠ” ì—­í• ì´ë‚˜ ë¶„ìœ„ê¸°ëŠ” ì–´ë–¤ í¸ì¸ê°€ìš”?",
    "ëˆ„êµ°ê°€ì—ê²Œ ì¤‘ìš”í•œ ì¼ì„ ë§¡ê¸°ê²Œ ë  ë•Œ, ì–´ë–¤ ë¶€ë¶„ì—ì„œ ì‹ ë¢°ë¥¼ ëŠë¼ì‹œë‚˜ìš”?",
    "ìƒˆë¡œìš´ ì‚¬ëŒê³¼ ì²˜ìŒ ë§Œë‚  ë•Œ, ì–´ë–¤ ì¸ìƒì„ ë°›ì„ ë•Œ ì•ˆì‹¬ì´ ë˜ì‹œë‚˜ìš”?",
    "ì•„ì´ì—ê²Œ ë§ì„ ê±¸ê±°ë‚˜ ëŒ€í™”í•  ë•Œ, ì–´ë–¤ ë§íˆ¬ë‚˜ í‘œí˜„ì„ ì¢‹ì•„í•˜ì„¸ìš”?",
    "ë¶€íƒí•œ ì¼ì´ ì •í™•í•˜ê²Œ ì´ë¤„ì¡Œì„ ë•Œ, ì–´ë–¤ ì ì—ì„œ â€˜ì˜ í•´ì£¼ì…¨ë‹¤â€™ê³  ëŠë¼ì‹œë‚˜ìš”?",
    "íŠ¹ë³„íˆ ë°”ì˜ê±°ë‚˜ ë„ì›€ì´ ê¸‰íˆ í•„ìš”í•  ë•Œ, ëŒë³´ë¯¸ê°€ ì–´ë–¤ íƒœë„ë¡œ ì‘ëŒ€í•´ì£¼ë©´ ì¢‹ì„ê¹Œìš”?",
]

# @app.get("/questions/caregiver")
# def get_caregiver_questions():
#     return JSONResponse(content={"questions": caregiver_questions})

# def format_caregiver_prompt(username: str, answers: list[str]) -> str:
#     formatted_qa = "\n".join([
#         f"{i+1}. {q}\në‹µë³€: {answers[i]}"
#         for i, q in enumerate(caregiver_questions)
#     ])
#     return f"""
#         ë‹¤ìŒì€ '{username}'ë¼ëŠ” ì•„ì´ëŒë³´ë¯¸ ì§€ì›ìì˜ ìê¸°ì†Œê°œ ë° ì§ˆë¬¸ ì‘ë‹µ ë‚´ìš©ì…ë‹ˆë‹¤.
#         ì•„ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ì„±ê²©ì„ ë”°ëœ»í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ 1ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:

#         {formatted_qa}

#         ì„±ê²© ìš”ì•½:
#         """

@app.post("/register")
def register_user(req: RegisterRequest, db: Session = Depends(get_db)):
    print("ğŸ’¡ ë°›ì€ req:", req.dict())
    if db.query(User).filter(User.email == req.email).first():
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë©”ì¼ì…ë‹ˆë‹¤.")

    hashed_pw = pwd_context.hash(req.password)
    new_user = User(
        username=req.username,
        email=req.email,
        hashed_password=hashed_pw,
        role=req.role,
        age=req.age,
        phone=req.phone
    )
    db.add(new_user)
    db.commit()
    db.refresh(new_user)

    # âœ… ëŒë³´ë¯¸ ê³„ì •ì´ë¼ë©´ Caregiver rowë„ ìƒì„±
    if req.role == UserRole.ëŒë³´ë¯¸:
        caregiver = Caregiver(
            user_id=new_user.id,
            age=req.age,

            # âœ… ë²¡í„° ì´ˆê¸°ê°’ (ëª¨ë‘ 0.0)
            parenting_style_vector=json.dumps([0.0] * 8),
            personality_traits_vector=json.dumps([0.0] * 10),
            communication_style_vector=json.dumps([0.0] * 5),
            caregiving_attitude_vector=json.dumps([0.0] * 6),
            handling_situations_vector=json.dumps([0.0] * 4),
            empathy_traits_vector=json.dumps([0.0] * 4),
            trust_time_vector=json.dumps([0.0] * 3)
        )

        # ëŒë³´ë¯¸ ì¡°ê±´ì´ ì…ë ¥ëœ ê²½ìš°
        if req.conditions:
            caregiver.available_days = ",".join(req.conditions.days)
            caregiver.available_times = json.dumps(req.conditions.times)
            caregiver.special_child = req.conditions.special
            caregiver.age_min = req.conditions.age_min
            caregiver.age_max = req.conditions.age_max

        db.add(caregiver)
        db.commit()
        logger.info(f"Caregiver row created for user_id={new_user.id}")

    return {
        "message": "íšŒì›ê°€ì… ì„±ê³µ",
        "user_id": new_user.id,
        "role": new_user.role.value
    }


@app.post("/login")
def login_user(req: LoginRequest, db: Session = Depends(get_db)):
    try:
        user = db.query(User).filter(User.email == req.email).first()
        if not user or not pwd_context.verify(req.password, user.hashed_password):
            raise HTTPException(status_code=401, detail="ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return {
            "access_token": f"dummy_token_for_{user.email}",
            "username": user.username,
            "role": user.role.value,
            "phone": user.phone,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
    

    
logger = logging.getLogger("main")

# @app.post("/user/preference")
# def save_user_preference(req: PreferenceRequest, db: Session = Depends(get_db)):
#     user = db.query(User).filter(User.email == req.email).first()
#     if not user:
#         raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

#     try:
#         # âœ… GPT ì„ë² ë”© ìƒì„± ë° ì§ë ¬í™”
#         embedding = embedding_model.embed_documents([req.summary])[0]
#         pickled_embedding = pickle.dumps(embedding)

#         # âœ… ê¸°ì¡´ preference ì¡´ì¬ ì‹œ update, ì—†ìœ¼ë©´ insert
#         existing_pref = db.query(UserPreference).filter_by(user_id=user.id).first()

#         if existing_pref:
#             # ğŸ”„ ê¸°ì¡´ preference ì—…ë°ì´íŠ¸
#             existing_pref.preferred_style = req.summary
#             existing_pref.embedding = pickled_embedding
#             logger.info(f"[ì—…ë°ì´íŠ¸] user_id={user.id}")
#         else:
#             # ğŸ†• ìƒˆë¡œìš´ preference ì¶”ê°€
#             new_pref = UserPreference(
#                 user_id=user.id,
#                 preferred_style=req.summary,
#                 embedding=pickled_embedding
#             )
#             db.add(new_pref)
#             logger.info(f"[ì‚½ì…] user_id={user.id}")

#         db.commit()
#         return {"message": "ì„±í–¥ ì €ì¥ ì™„ë£Œ"}

#     except Exception as e:
#         db.rollback()
#         logger.error(f"ì„±í–¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
#         raise HTTPException(status_code=500, detail="ì„±í–¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
    
    
class UserChatRequest(BaseModel):
    email: str
    history: List[str]
    
    
# SBERT ëª¨ë¸ ì´ˆê¸°í™”
sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

def generate_summary_with_gpt(history: List[str], role: str) -> str:
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½"""
    prompt = f"""
        ë‹¹ì‹ ì€ {role}ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {role}ì˜ ì„±í–¥ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
        ìš”ì•½ì€ ë‹¤ìŒ 7ê°œ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        1. ì–‘ìœ¡ ìŠ¤íƒ€ì¼ (êµìœ¡, ì •ì„œ, ììœ¨ì„±, í›ˆìœ¡, ë†€ì´, ì•ˆì „, ì• ì°©, ì‹ ì²´í™œë™)
        2. ì„±ê²© íŠ¹ì„± (ì™¸í–¥ì„±, ë‚´í–¥ì„±, ê°ì„±, ì´ì„±, ìœµí†µì„±, ì›ì¹™ì„±, ê¼¼ê¼¼í•¨, ììœ ë¡œì›€, ìœ ë¨¸, ì¹¨ì°©í•¨)
        3. ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼ (ì„¤ëª…, ì§ê´€, ëŒ€í™”, ë¹„ì–¸ì–´, ì§€ì‹œ)
        4. ëŒë´„ íƒœë„ (ì¸ë‚´ì‹¬, ì ê·¹ì„±, ì‹ ë¢°, ê°œì…, ê´€ì°°, ë…ë¦½)
        5. ìƒí™© ëŒ€ì²˜ (ê°ˆë“±, ëŒë°œìƒí™©, ê³„íš, ìœ ì—°ì„±)
        6. ê³µê° íŠ¹ì„± (ê°ì •ë¯¼ê°ì„±, ê³µê°, ë¬´ë˜í•¨, í‘œí˜„)
        7. ì‹ ë¢°/ì‹œê°„ (ì‹œê°„ì—„ìˆ˜, ìœµí†µì„±, ì‹ ë¢°)

        ëŒ€í™” ë‚´ìš©:
        {chr(10).join(history)}

        ìš”ì•½:
    """

    try:
        response = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ {role}ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"GPT ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return ""

def generate_vectors_from_summary(summary: str) -> Dict[str, List[float]]:
    """SBERTë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ë¬¸ì„ ë²¡í„°í™”"""
    try:
        # ê° ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± ì •ì˜
        categories = {
            "parenting_style_vector": [
                "êµìœ¡ ì¤‘ì‹¬", "ì •ì„œ ì¼€ì–´ ì¤‘ì‹¬", "ììœ¨ì„± ì¤‘ì‹¬", "í›ˆìœ¡ ì¤‘ì‹¬",
                "ë†€ì´ ì¤‘ì‹¬", "ì•ˆì „/ë³´í˜¸ ì¤‘ì‹¬", "ì• ì°© ì¤‘ì‹¬", "ì‹ ì²´ í™œë™ ì¤‘ì‹¬"
            ],
            "personality_traits_vector": [
                "ì™¸í–¥ì ", "ë‚´í–¥ì ", "ê°ì„±í˜•", "ì´ì„±í˜•", "ìœµí†µí˜•", "ì›ì¹™í˜•",
                "ê¼¼ê¼¼í˜•", "ììœ í˜•", "ìœ ë¨¸í˜•", "ì¹¨ì°©í˜•"
            ],
            "communication_style_vector": [
                "ì„¤ëª… ì¤‘ì‹¬", "ì§ê´€ ì¤‘ì‹¬", "ëŒ€í™”í˜•", "ë¹„ì–¸ì–´í˜•", "ì§€ì‹œí˜•"
            ],
            "caregiving_attitude_vector": [
                "ì¸ë‚´ì‹¬ ìˆëŠ”", "ì ê·¹ì ì¸", "ì‹ ë¢° ì¤‘ì‹¬", "ê°œì…í˜•", "ê´€ì°°í˜•", "ë…ë¦½ ìœ ë„í˜•"
            ],
            "handling_situations_vector": [
                "ê°ˆë“± ì¤‘ì¬í˜•", "ëŒë°œ ìƒí™© ëŒ€ì‘í˜•", "ê³„íší˜•", "ìœ ì—° ëŒ€ì‘í˜•"
            ],
            "empathy_traits_vector": [
                "ê°ì • ë¯¼ê°í˜•", "ê³µê° ìš°ì„ í˜•", "ë¬´ë˜í•œ í˜•", "ê°ì • í‘œí˜„í˜•"
            ],
            "trust_time_vector": [
                "ì‹œê°„ ì—„ìˆ˜í˜•", "ìœµí†µì„± ìˆëŠ”", "ì‹ ë¢° ìš°ì„ í˜•"
            ]
        }
        sbert_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        # ìš”ì•½ë¬¸ì„ SBERTë¡œ ì„ë² ë”©
        summary_embedding = sbert_model.encode(summary)

        # ê° ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì„± ë²¡í„° ìƒì„±
        category_embeddings = {}
        for category, traits in categories.items():
            # ê° íŠ¹ì„±ì„ SBERTë¡œ ì„ë² ë”©
            trait_embeddings = sbert_model.encode(traits)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = []
            for trait_emb in trait_embeddings:
                similarity = np.dot(summary_embedding, trait_emb) / (
                    np.linalg.norm(summary_embedding) * np.linalg.norm(trait_emb)
                )
                similarities.append(float(similarity))
            
            # # ìœ ì‚¬ë„ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
            # similarities = np.array(similarities)
            # similarities = (similarities - similarities.min()) / (similarities.max() - similarities.min() + 1e-8)
            
            # category_embeddings[category] = similarities.tolist()
            
            # softmax ì‚¬ìš©
            similarities = np.array(similarities)
            softmax_similarities = softmax(similarities)
            category_embeddings[category] = softmax_similarities.tolist()

        return category_embeddings

    except Exception as e:
        print(f"ë²¡í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {}
    

    
@app.post("/user/preference/from-chat")
def generate_preference_from_chat(req: UserChatRequest, db: Session = Depends(get_db)):
    try:
        # GPTë¡œ ìš”ì•½ ìƒì„±
        summary = generate_summary_with_gpt(req.history, "ê³ ê°")
        if not summary:
            raise HTTPException(status_code=500, detail="ìš”ì•½ ìƒì„± ì‹¤íŒ¨")

        # SBERTë¡œ ë²¡í„° ìƒì„±
        vectors = generate_vectors_from_summary(summary)
        if not vectors:
            raise HTTPException(status_code=500, detail="ë²¡í„° ìƒì„± ì‹¤íŒ¨")

        # ì‚¬ìš©ì ì°¾ê¸°
        user = db.query(User).filter(User.email == req.email).first()
        if not user:
            raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ë²¡í„°ë§Œ ë°˜í™˜ (DB ì €ì¥ ì—†ì´)
        return JSONResponse(content={
            "message": "ì„±í–¥ ë²¡í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "vectors": vectors
        })

    except Exception as e:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", str(e))
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

class RecommendationRequest(BaseModel):
    vectors: Dict[str, List[float]]  # history ëŒ€ì‹  vectorsë¥¼ ë°›ë„ë¡ ìˆ˜ì •
    history: List[str]  # ê°€ì¤‘ì¹˜ ê³„ì‚°ì„ ìœ„í•´ í•„ìš”
    conditions: Optional[Dict] = {}

def calculate_dynamic_weights(history: List[str]) -> Dict[str, float]:
    """ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬ë³„ ê°€ì¤‘ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ê³„ì‚°"""
    try:
        # ê¸°ë³¸ ê°€ì¤‘ì¹˜
        default_weights = {
            "parenting_style_vector": 0.25,
            "personality_traits_vector": 0.20,
            "communication_style_vector": 0.15,
            "caregiving_attitude_vector": 0.15,
            "handling_situations_vector": 0.10,
            "empathy_traits_vector": 0.10,
            "trust_time_vector": 0.05
        }

        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜
        category_keywords = {
            "parenting_style_vector": ["êµìœ¡", "í•™ìŠµ", "ë†€ì´", "ì•ˆì „", "ë³´í˜¸", "ì• ì°©", "ì‹ ì²´í™œë™", "ììœ¨ì„±", "í›ˆìœ¡"],
            "personality_traits_vector": ["ì„±ê²©", "ì„±í–¥", "ì™¸í–¥ì ", "ë‚´í–¥ì ", "ê°ì„±", "ì´ì„±", "ìœµí†µì„±", "ì›ì¹™", "ê¼¼ê¼¼", "ììœ ", "ìœ ë¨¸", "ì¹¨ì°©"],
            "communication_style_vector": ["ëŒ€í™”", "ì„¤ëª…", "ì§ê´€", "ë¹„ì–¸ì–´", "ì§€ì‹œ", "ì†Œí†µ"],
            "caregiving_attitude_vector": ["ì¸ë‚´ì‹¬", "ì ê·¹ì ", "ì‹ ë¢°", "ê°œì…", "ê´€ì°°", "ë…ë¦½"],
            "handling_situations_vector": ["ê°ˆë“±", "ëŒë°œìƒí™©", "ê³„íš", "ìœ ì—°", "ëŒ€ì²˜"],
            "empathy_traits_vector": ["ê°ì •", "ê³µê°", "ë¬´ë˜", "í‘œí˜„"],
            "trust_time_vector": ["ì‹œê°„", "ì—„ìˆ˜", "ìœµí†µì„±", "ì‹ ë¢°"]
        }

        # ëŒ€í™” ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
        combined_text = " ".join(history)
        
        # SBERTë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš© ì„ë² ë”©
        text_embedding = sbert_model.encode(combined_text)
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
        category_scores = {}
        for category, keywords in category_keywords.items():
            # í‚¤ì›Œë“œë“¤ì„ SBERTë¡œ ì„ë² ë”©
            keyword_embeddings = sbert_model.encode(keywords)
            
            # ê° í‚¤ì›Œë“œì™€ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = []
            for keyword_emb in keyword_embeddings:
                similarity = np.dot(text_embedding, keyword_emb) / (
                    np.linalg.norm(text_embedding) * np.linalg.norm(keyword_emb)
                )
                similarities.append(float(similarity))
            
            # ìµœëŒ€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì ìˆ˜ë¡œ ì‚¬ìš©
            category_scores[category] = max(similarities)

        # ì ìˆ˜ ì •ê·œí™”
        total_score = sum(category_scores.values())
        if total_score > 0:
            normalized_scores = {k: v/total_score for k, v in category_scores.items()}
        else:
            normalized_scores = default_weights

        # ê¸°ë³¸ ê°€ì¤‘ì¹˜ì™€ ì •ê·œí™”ëœ ì ìˆ˜ë¥¼ ê²°í•© (70:30 ë¹„ìœ¨)
        final_weights = {
            category: 0.7 * default_weights[category] + 0.3 * normalized_scores[category]
            for category in default_weights.keys()
        }

        # ê°€ì¤‘ì¹˜ ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
        total_weight = sum(final_weights.values())
        final_weights = {k: v/total_weight for k, v in final_weights.items()}

        return final_weights

    except Exception as e:
        print(f"ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return default_weights
    
def normalize_vectors(vectors: Dict[str, List[float]]) -> Dict[str, List[float]]:
    """ê° ì¹´í…Œê³ ë¦¬ë³„ ë²¡í„°ë¥¼ ì •ê·œí™”"""
    normalized = {}
    for category, vec in vectors.items():
        vec_array = np.array(vec)
        norm = np.linalg.norm(vec_array)
        if norm > 0:
            normalized[category] = (vec_array / norm).tolist()
        else:
            normalized[category] = vec
    return normalized

@app.post("/recommend/caregiver")
async def recommend_caregiver(req: RecommendationRequest, db: Session = Depends(get_db)):
    try:
        print("ğŸ“¨ ë°›ì€ JSON ë°ì´í„°:")
        print("vectors:", json.dumps(req.vectors, indent=2, ensure_ascii=False))
        print("history:", json.dumps(req.history, indent=2, ensure_ascii=False))
        print("conditions:", json.dumps(req.conditions, indent=2, ensure_ascii=False))

        vectors = req.vectors
        if not vectors:
            raise HTTPException(status_code=400, detail="ë²¡í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        weights = calculate_dynamic_weights(req.history)
        print(weights)
        # âœ… 1. ì¡°ê±´ ê¸°ë°˜ í•„í„°ë§
        query = db.query(Caregiver)
        cond = req.conditions or {}

        # ğŸ—“ ìš”ì¼ ì¡°ê±´
        if cond.get("available_days"):
            for day in cond["available_days"]:
                query = query.filter(Caregiver.available_days.like(f"%{day}%"))

        # ğŸ‘¶ íŠ¹ìˆ˜ì•„ë™ ì¡°ê±´
        if cond.get("special_child_required") == "O":
            query = query.filter(Caregiver.special_child == True)
        elif cond.get("special_child_required") == "X":
            query = query.filter(Caregiver.special_child == False)

        # ğŸ‘§ ì—°ë ¹ ì¡°ê±´
        age = cond.get("age")
        if age is not None:
            query = query.filter(
                Caregiver.age_min <= age,
                Caregiver.age_max >= age
            )

        # ê²°ê³¼ ì¡°íšŒ
        caregivers = query.all()
        print(f"ğŸ” ì¡°ê±´ í•„í„° í›„ ì „ì²´ ëŒë³´ë¯¸ ìˆ˜: {len(caregivers)}")

        filtered_caregivers = []

        if cond.get("available_times"):
            desired_slots = cond["available_times"]  # ë¶€ëª¨ê°€ ì›í•˜ëŠ” ì‹œê°„ëŒ€ ë¦¬ìŠ¤íŠ¸

            for caregiver in caregivers:
                try:
                    caregiver_slots = json.loads(caregiver.available_times)
                except:
                    continue

                matched = False
                for parent_slot in desired_slots:
                    for care_slot in caregiver_slots:
                        # ë¶€ëª¨ì˜ ì›í•˜ëŠ” ì‹œê°„ì´ ëŒë³´ë¯¸ ë²”ìœ„ ì•ˆì— í¬í•¨ë˜ëŠ”ì§€ ê²€ì‚¬
                        if parent_slot["start"] >= care_slot["start"] and parent_slot["end"] <= care_slot["end"]:
                            matched = True
                            break
                    if matched:
                        break

                if matched:
                    filtered_caregivers.append(caregiver)
        else:
            # ì‹œê°„ ì¡°ê±´ ì—†ìœ¼ë©´ ì „ë¶€ í¬í•¨
            filtered_caregivers = caregivers

        print(f"âœ… ì‹œê°„ ì¡°ê±´ ë°˜ì˜ í›„ ëŒë³´ë¯¸ ìˆ˜: {len(filtered_caregivers)}")
        caregivers=filtered_caregivers

        #caregivers = db.query(Caregiver).all() 
        #print(f"âœ… ì¡°ê±´ í•„í„° í›„ ë‚¨ì€ ëŒë³´ë¯¸ ìˆ˜: {len(caregivers)}")
        similarities = []

        # âœ… 2. ë²¡í„° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
        for caregiver in caregivers:
            caregiver_vectors = {
                "parenting_style_vector": json.loads(caregiver.parenting_style_vector),
                "personality_traits_vector": json.loads(caregiver.personality_traits_vector),
                "communication_style_vector": json.loads(caregiver.communication_style_vector),
                "caregiving_attitude_vector": json.loads(caregiver.caregiving_attitude_vector),
                "handling_situations_vector": json.loads(caregiver.handling_situations_vector),
                "empathy_traits_vector": json.loads(caregiver.empathy_traits_vector),
                "trust_time_vector": json.loads(caregiver.trust_time_vector)
            }
            caregiver_vectors = normalize_vectors(caregiver_vectors)

            category_similarities = {}
            for category in vectors.keys():
                user_vec = np.array(vectors[category])
                care_vec = np.array(caregiver_vectors[category])
                similarity = np.dot(user_vec, care_vec) / (
                    np.linalg.norm(user_vec) * np.linalg.norm(care_vec)
                )
                category_similarities[category] = float(similarity)

            total_similarity = sum(
                category_similarities[cat] * weights[cat]
                for cat in weights.keys()
            )

            similarities.append((total_similarity, caregiver, category_similarities))

        top3 = sorted(similarities, key=lambda x: x[0], reverse=True)[:3]

        result = []
        for total_sim, caregiver, cat_sims in top3:
            explanation = generate_recommendation_explanation(caregiver, vectors, cat_sims)
            result.append({
                "name": caregiver.user.username,
                "age": caregiver.age,
                "total_similarity": round(total_sim, 4),
                "category_similarities": {
                    cat: round(sim, 4) for cat, sim in cat_sims.items()
                },
                "explanation": explanation
            })

        return {"recommendations": result}

    except Exception as e:
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", str(e))
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))

# ë²¡í„° DB ê²½ë¡œ ì„¤ì • (vectorDB í´ë”ì— chroma.sqlite3 í¬í•¨)
VECTOR_DB_DIR = os.path.join(os.path.dirname(__file__), "vectorDB")
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ë²¡í„° DB ë¡œë“œ
vector_db = Chroma(
    persist_directory=VECTOR_DB_DIR,
    embedding_function=embedding_model
)

@app.post("/ask/")
def ask_question(req: QueryRequest):
    try:
        # ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_db.similarity_search(req.prompt, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        # ğŸ§  GPT ì‘ë‹µ ìƒì„± (RAG + ë‹¤ìŒ ì§ˆë¬¸ ìœ ë„)
        prompt = f"""
            ë„ˆëŠ” ì‚¬ìš©ìì™€ ê°ì •ì ìœ¼ë¡œ ì—°ê²°ë˜ë©°, ìœ¡ì•„ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì£¼ì œì—ì„œ ì„±í–¥ì„ íŒŒì•…í•˜ê³  ì ì ˆí•œ ëŒë³´ë¯¸ ë§¤ì¹­ì„ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼.
            ì•„ë˜ ì°¸ê³  ì •ë³´ë¥¼ í™œìš©í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë”°ëœ»í•˜ê²Œ ë‹µë³€í•´ì¤˜. ì•„ì´ì˜ ì„±í–¥ì„ ì–˜ê¸°í•˜ë©´ ê·¸ì— ì í•©í•œ ëŒë³´ë¯¸ë¥¼ ë§¤ì¹­í•´ì£¼ëŠ” ê±°ì•¼. 
            ê·¸ë¦¬ê³  ì„±í–¥ì„ ì˜ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ í•­ìƒ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì„ ì´ì–´ê°€ë„ë¡ í•´ì¤˜.
            ë¬¸ë§¥ì— ë”°ë¼ ì‚¬ìš©ìê°€ í˜ë“¤ì–´í•˜ê±°ë‚˜ ì‹¬ë¦¬ì ìœ¼ë¡œ ë¶ˆì•ˆì •í•˜ë©´ ìœ„ë¡œí•´ì¤˜. í•˜ì§€ë§Œ ì œì¼ ìš°ì„ í•´ì•¼í•  ê²ƒì€ ëŒë³´ë¯¸ ë§¤ì¹­ì„ ìœ„í•œ ì„±í–¥ íŒŒì•…ì´ì•¼.
            ê²°ê³¼ì ìœ¼ë¡œ ë„ˆëŠ” ëŒë³´ë¯¸ ë§¤ì¹­ì„ ìœ„í•´ ì¡´ì¬í•˜ëŠ”ê±°ì•¼. ëŒë³´ë¯¸ ë§¤ì¹­ì´ ìµœìš°ì„ ì´ì•¼. ëŒë³´ë¯¸=ë³´ëª¨=ë³´í˜¸ì
            [ì°¸ê³  ì •ë³´]
            {context}

            [ì§ˆë¬¸]
            {req.prompt}

            [ë‹µë³€]
            """
        
        gpt_result = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì„¬ì„¸í•˜ê³  ë”°ëœ»í•œ ìœ¡ì•„ ìƒë‹´ì‚¬ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        answer = gpt_result.choices[0].message.content.strip()
        return {"answer": answer}

    except Exception as e:
        logger.error(f"/ask/ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
    



    
@app.get("/parent/info")
def get_parent_info(email: str, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.email == email).first()
    if not user or not user.parent:
        raise HTTPException(status_code=404, detail="ë¶€ëª¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    parent = user.parent
    return {
        "children_count": parent.children_count,
        "is_multi_child": parent.is_multi_child,
        "income_type": parent.income_type,
        "preferred_service": parent.service_type_name,
        "last_calculated_fee": parent.last_calculated_fee,
        "hours": parent.hours,
        "hourly_fee": parent.hourly_fee,
        "total_fee": parent.total_fee,
        "gov_support_fee": parent.gov_support_fee
    }

#  ëŒë³´ë¯¸ ëŒ€í™” â†’ GPT ì‘ë‹µ ìƒì„± (RAG)
@app.post("/rag/")
def caregiver_rag_response(req: QueryRequest):
    try:
        docs = vector_db.similarity_search(req.prompt, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        prompt = f"""
                ë‹¹ì‹ ì€ ìœ¡ì•„ì™€ ëŒë´„, ê´€ë ¨ ì„œë¹„ìŠ¤ ë° ì •ì±…ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
                ì‚¬ìš©ìê°€ ê¶ê¸ˆí•œ ì ì´ë‚˜ ìš”ì²­í•˜ëŠ” ë‚´ìš©ì„ ì´í•´í•˜ê³ ,
                ìµœëŒ€í•œ ì‰½ê²Œ ì„¤ëª…í•˜ë©°, í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.
                ì‚¬ìš©ìê°€ í¸ì•ˆí•˜ê²Œ ëŒ€í™”í•  ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ìœ ì§€í•´ ì£¼ì„¸ìš”.
                
                ğŸ§¾ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë°°ê²½ ë¬¸ì„œ:
                {context}
                
                [ì§€ì›ì]
                {req.prompt}

                """

        gpt_result = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì„¬ì„¸í•˜ê³  ë”°ëœ»í•œ ìœ¡ì•„ ìƒë‹´ì‚¬ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        answer = gpt_result.choices[0].message.content.strip()
        return {"answer": answer}

    except Exception as e:
        logger.error(f"/rag/ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")


from pydantic import BaseModel
from typing import List, Dict, Optional
import json, re
from fastapi import HTTPException, Depends
from sqlalchemy.orm import Session

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸš© Pydantic Models
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ChatHistoryRequest(BaseModel):
    email: str
    history: List[str]

class VectorResponse(BaseModel):
    vectors: Dict[str, List[float]]

class VectorUpdateRequest(BaseModel):
    email: str
    parenting_style_vector: Optional[List[float]] = None
    personality_traits_vector: Optional[List[float]] = None
    communication_style_vector: Optional[List[float]] = None
    caregiving_attitude_vector: Optional[List[float]] = None
    handling_situations_vector: Optional[List[float]] = None
    empathy_traits_vector: Optional[List[float]] = None
    trust_time_vector: Optional[List[float]] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸš© ì„±í–¥ ì¶”ì¶œ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 
import traceback

@app.post("/caregiver/personality/from-chat")
def analyze_personality_from_chat(data: ChatHistoryRequest, db: Session = Depends(get_db)):
    try:
        # ì„±í–¥ ì¹´í…Œê³ ë¦¬ ì •ì˜
        categories = {
            "parenting_style_vector": [
                "êµìœ¡ ì¤‘ì‹¬", "ì •ì„œ ì¼€ì–´ ì¤‘ì‹¬", "ììœ¨ì„± ì¤‘ì‹¬", "í›ˆìœ¡ ì¤‘ì‹¬",
                "ë†€ì´ ì¤‘ì‹¬", "ì•ˆì „/ë³´í˜¸ ì¤‘ì‹¬", "ì• ì°© ì¤‘ì‹¬", "ì‹ ì²´ í™œë™ ì¤‘ì‹¬"
            ],
            "personality_traits_vector": [
                "ì™¸í–¥ì ", "ë‚´í–¥ì ", "ê°ì„±í˜•", "ì´ì„±í˜•", "ìœµí†µí˜•", "ì›ì¹™í˜•",
                "ê¼¼ê¼¼í˜•", "ììœ í˜•", "ìœ ë¨¸í˜•", "ì¹¨ì°©í˜•"
            ],
            "communication_style_vector": [
                "ì„¤ëª… ì¤‘ì‹¬", "ì§ê´€ ì¤‘ì‹¬", "ëŒ€í™”í˜•", "ë¹„ì–¸ì–´í˜•", "ì§€ì‹œí˜•"
            ],
            "caregiving_attitude_vector": [
                "ì¸ë‚´ì‹¬ ìˆëŠ”", "ì ê·¹ì ì¸", "ì‹ ë¢° ì¤‘ì‹¬", "ê°œì…í˜•", "ê´€ì°°í˜•", "ë…ë¦½ ìœ ë„í˜•"
            ],
            "handling_situations_vector": [
                "ê°ˆë“± ì¤‘ì¬í˜•", "ëŒë°œ ìƒí™© ëŒ€ì‘í˜•", "ê³„íší˜•", "ìœ ì—° ëŒ€ì‘í˜•"
            ],
            "empathy_traits_vector": [
                "ê°ì • ë¯¼ê°í˜•", "ê³µê° ìš°ì„ í˜•", "ë¬´ë˜í•œ í˜•", "ê°ì • í‘œí˜„í˜•"
            ],
            "trust_time_vector": [
                "ì‹œê°„ ì—„ìˆ˜í˜•", "ìœµí†µì„± ìˆëŠ”", "ì‹ ë¢° ìš°ì„ í˜•"
            ]
        }

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = (
            "ë‹¹ì‹ ì€ 'ëŒë³´ë¯¸ ì„±í–¥ ìê°€ì§„ë‹¨ ì±—ë´‡'ì…ë‹ˆë‹¤.\n"
            "ì§€ì›ìëŠ” ëŒë³´ë¯¸ë¡œì„œ ë³¸ì¸ì˜ ëŒë´„ ì„±í–¥ê³¼ ê°€ì¹˜ê´€ì„ ì´í•´í•˜ê³ ì ìê°€ì§„ë‹¨ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\n"
            "ì•„ë˜ ëŒ€í™”ëŠ” ì‹¤ì œ ëŒë´„ ìƒí™©ì„ ê°€ì •í•œ ì—­í• ê·¹ ì§ˆë¬¸ê³¼ ì§€ì›ìì˜ ì‘ë‹µì…ë‹ˆë‹¤.\n"
            "ì´ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ 7ê°œì˜ ì„±í–¥ í•­ëª©ì— ëŒ€í•´ 0~1 ì‚¬ì´ì˜ ìˆ˜ì¹˜ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n"
            "\n"
            "1) parenting_style_vector (ì´ 8ê°œ í•­ëª©)\n"
            "2) personality_traits_vector (ì´ 10ê°œ í•­ëª©)\n"
            "3) communication_style_vector (ì´ 5ê°œ í•­ëª©)\n"
            "4) caregiving_attitude_vector (ì´ 6ê°œ í•­ëª©)\n"
            "5) handling_situations_vector (ì´ 4ê°œ í•­ëª©)\n"
            "6) empathy_traits_vector (ì´ 4ê°œ í•­ëª©)\n"
            "7) trust_time_vector (ì´ 3ê°œ í•­ëª©)\n"
            "\n"
            "ê° í•­ëª©ì€ ë°˜ë“œì‹œ í•´ë‹¹ ê°œìˆ˜ë§Œí¼ì˜ float ê°’ì´ ë“¤ì–´ê°„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "ê°’ì€ 0.0 ì´ìƒ 1.0 ì´í•˜ì˜ ìˆ˜ì¹˜ì´ë©°, ì§€ì›ìì˜ ì‘ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ì„±í–¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.\n"
            "\n"
            "â— íŒë‹¨ì´ ì–´ë ¤ìš´ í•­ëª©ì€ 0.1ë¡œ ì„¤ì •í•˜ì„¸ìš”.\n"
            "â— íŒë‹¨ì´ ê°€ëŠ¥í•œ í•­ëª©ë§Œ 0.1ì´ ì•„ë‹Œ ìˆ˜ì¹˜ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n"
            "â— í•­ëª©ë³„ë¡œ ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ëŠ” ì •í™•íˆ ë§ì¶°ì•¼ í•˜ë©°, ìƒëµí•˜ê±°ë‚˜ ì˜ëª»ëœ ê¸¸ì´ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "\n"
            "âœ… ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "\n"
            "{\n"
            "  \"vectors\": {\n"
            "    \"parenting_style_vector\": [0.2, 0.1, 0.5, 0.1, 0.3, 0.1, 0.1, 0.6],\n"
            "    \"personality_traits_vector\": [0.1, 0.8, 0.1, 0.1, 0.5, 0.6, 0.1, 0.3, 0.1, 0.1],\n"
            "    \"communication_style_vector\": [0.7, 0.1, 0.1, 0.1, 0.1],\n"
            "    \"caregiving_attitude_vector\": [0.6, 0.1, 0.8, 0.1, 0.1, 0.1],\n"
            "    \"handling_situations_vector\": [0.1, 0.1, 0.5, 0.1],\n"
            "    \"empathy_traits_vector\": [0.4, 0.1, 0.1, 0.7],\n"
            "    \"trust_time_vector\": [0.3, 0.1, 0.1]\n"
            "  }\n"
            "}\n"
            "\n"
            "ğŸ§¾ ë¶„ì„ì€ ì•„ë˜ ìê°€ì§„ë‹¨ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”:\n"
            + "\n".join(data.history)
        )

        # GPT í˜¸ì¶œ
        gpt_response = client.chat.completions.create(
            model=chat_model,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë‹¹ì‹ ì€ ëŒë³´ë¯¸ ì„±í–¥ì„ ë¶„ì„í•˜ëŠ” ì •ëŸ‰í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n"
                        "ì§€ì›ìëŠ” 15ê°œì˜ ì—­í• ê·¹ì„ ê¸°ë°˜ìœ¼ë¡œ ìê°€ì§„ë‹¨ì„ ìˆ˜í–‰í–ˆìœ¼ë©°, ë‹¹ì‹ ì€ ë‹¤ìŒê³¼ ê°™ì€ í•­ëª©ì„ ì •ëŸ‰ì ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”."
                    )
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3
        )

        # GPT ì‘ë‹µ ì¶”ì¶œ
        raw = gpt_response.choices[0].message.content.strip()
        print("ğŸ“¨ GPT ì‘ë‹µ ì›ë¬¸:\n", raw)

        # (2) JSON ì¶”ì¶œ ì‹œ ê´„í˜¸ ë§¤ì¹­ ë³´ì™„
        match = re.search(r"\{[\s\S]*\}", raw)
        if not match:
            print("â— GPT ì‘ë‹µì— JSON í˜•ì‹ì´ ì—†ì–´ ê¸°ë³¸ ë²¡í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")

            # ê¸°ë³¸ ë²¡í„° ìƒì„± (í•­ëª© ìˆ˜ ê¸°ë°˜)
            default_vectors = {
                key: [0.1] * len(value)
                for key, value in categories.items()
            }

            return JSONResponse(content={"vectors": default_vectors})

        json_str = match.group()
        if not json_str.strip().endswith("}"):
            json_str += "}"  # í˜¹ì‹œ ëˆ„ë½ëì„ ê²½ìš° ëŒ€ë¹„

        print("ğŸ“¤ ì¶”ì¶œëœ JSON ë¬¸ìì—´:\n", json_str)

        # (3) JSON íŒŒì‹±
        parsed = json.loads(json_str)

        return JSONResponse(content=parsed)

    except json.JSONDecodeError as e:
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ì˜ˆì™¸ ë°œìƒ: {e}")



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸš© DB ì €ì¥ API
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.post("/caregiver/update-vectors")
def update_caregiver_vectors(data: VectorUpdateRequest, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.email == data.email).first()
    if not user:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì´ë©”ì¼ì˜ ì‚¬ìš©ìê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    caregiver = db.query(Caregiver).filter(Caregiver.user_id == user.id).first()
    if not caregiver:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì‚¬ìš©ìëŠ” ëŒë³´ë¯¸ê°€ ì•„ë‹™ë‹ˆë‹¤.")

    vector_fields = [
        "parenting_style_vector",
        "personality_traits_vector",
        "communication_style_vector",
        "caregiving_attitude_vector",
        "handling_situations_vector",
        "empathy_traits_vector",
        "trust_time_vector"
    ]

    for field in vector_fields:
        value = getattr(data, field)
        if value is not None:
            setattr(caregiver, field, json.dumps(value))

    db.commit()
    return {"message": "ëŒë³´ë¯¸ ì„±í–¥ ë²¡í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."}

def generate_recommendation_explanation(caregiver: Caregiver, user_vectors: Dict, category_similarities: Dict) -> str:
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œ ì´ìœ ë¥¼ ê°ì„±ì ìœ¼ë¡œ ì„¤ëª…"""
    # ì „ì²´ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    total_similarity = sum(category_similarities.values()) / len(category_similarities)
    
    prompt = f"""
        ë‹¹ì‹ ì€ ë”°ëœ»í•œ ê³µê° ëŠ¥ë ¥ì„ ì§€ë‹Œ ìœ¡ì•„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
        ì•„ë˜ â€˜ëŒë³´ë¯¸ ì •ë³´â€™ì™€ â€˜ì‚¬ìš©ì ê°ì •Â·ì„±í–¥ ë²¡í„°â€™ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ,  
        ì™œ ì´ ëŒë³´ë¯¸ê°€ ì‚¬ìš©ìì—ê²Œ ì í•©í•œì§€ ê³µê° ì–´ë¦° ë§íˆ¬ë¡œ ì •ì„±ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

        â€» ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ê³¼ ë¬¸ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¦…ë‹ˆë‹¤.  
        â€» íŠ¹íˆ â€˜ì¹´í…Œê³ ë¦¬ë³„ ê°•ì  Top 3â€™ì˜ ê° í•­ëª© ì´ë¦„ì€ í•œêµ­ì–´ë¡œë§Œ í‘œê¸°í•˜ê³ ,  
        ì„¤ëª…ì€ ë”°ëœ»í•˜ê³  êµ¬ì²´ì ì´ë©° ì‚¬ìš©ì ê´€ì ì—ì„œ ê³µê°í•˜ë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.  
        â€» ì´ëª¨ì§€ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        <ì¶”ì²œ ì´ìœ >

        â–  ì–´ë–¤ ëŒë³´ë¯¸ì¼ê¹Œ?
        ì´ ëŒë³´ë¯¸ëŠ” ì‚¬ìš©ìì˜ ê°ì •ê³¼ ì„±í–¥ì—ì„œ íŠ¹íˆ **ã€ˆìœ ì‚¬ë„ ìƒìœ„ 1ìœ„ í•­ëª©ã€‰**, **ã€ˆìœ ì‚¬ë„ ìƒìœ„ 2ìœ„ í•­ëª©ã€‰** ê°™ì€ ì¸¡ë©´ì—ì„œ ê¹Šì´ ê³µê°í•  ìˆ˜ ìˆëŠ” íŠ¹ì„±ì´ ìˆìœ¼ë©°, ì•„ì´ì—ê²Œ ì•ˆì •ì ì´ê³  ë”°ëœ»í•œ ëŒë´„ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ì ì„ìì…ë‹ˆë‹¤.

        â–  ì¹´í…Œê³ ë¦¬ë³„ ê°•ì  Top 3  
        1. ã€ˆìœ ì‚¬ë„ ìƒìœ„ 1ìœ„ í•­ëª©ã€‰: í•´ë‹¹ íŠ¹ì„±ì´ ì–´ë–»ê²Œ ì‚¬ìš©ìì™€ ê¹Šì´ í†µí•˜ê³  ì•„ì´ ëŒë´„ì— ê¸ì •ì ìœ¼ë¡œ ì‘ìš©í•˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.  
        2. ã€ˆìœ ì‚¬ë„ ìƒìœ„ 2ìœ„ í•­ëª©ã€‰: ìœ„ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê³µê° ì–´ë¦° ì„¤ëª…ì„ ì ì–´ ì£¼ì„¸ìš”.  
        3. ã€ˆìœ ì‚¬ë„ ìƒìœ„ 3ìœ„ í•­ëª©ã€‰: ìœ„ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê³µê° ì–´ë¦° ì„¤ëª…ì„ ì ì–´ ì£¼ì„¸ìš”.  

        â–  ì´ ëŒë³´ë¯¸ëŠ” ì–´ë–»ê²Œ ëŒ€ì‘í• ê¹Œ?
        ì‹¤ì œ ëŒë´„ ìƒí™©ì—ì„œ ì´ ëŒë³´ë¯¸ê°€ ë³´ì—¬ ì¤„ ë°˜ì‘ì„ í•œ ê°€ì§€ ì˜ˆë¡œ ë“¤ì–´ ì„œìˆ í•œ ë’¤,  
        ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•œ ì¡°ì–¸ì´ë‚˜ ìœ„ë¡œì˜ ë§ì„ ë§ë¶™ì—¬ ì£¼ì„¸ìš”.  
        ì˜ˆì‹œ ìƒí™©ì€ ì•„ì´ê°€ ë‚¯ì„  í™˜ê²½ì—ì„œ ë¶ˆì•ˆí•´í•  ë•Œ, ë†€ì´ ì¤‘ ê°ˆë“±ì´ ìƒê¸¸ ë•Œ ë“±ìœ¼ë¡œ ììœ ë¡­ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.

        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ì£¼ì˜ ì‚¬í•­  
        - ê° ì œëª©(ì–´ë–¤ ëŒë³´ë¯¸ì¼ê¹Œ, ì¹´í…Œê³ ë¦¬ë³„ ê°•ì  Top 3, ì´ ëŒë³´ë¯¸ëŠ” ì–´ë–»ê²Œ ëŒ€ì‘í• ê¹Œ)ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.  
        - ëª¨ë“  ì„¤ëª…ì€ â€˜ê³µê° + ê´€ì°° ê¸°ë°˜ + ì‚¬ìš©ì ê´€ì ê³¼ì˜ ì—°ê²°â€™ì´ ë˜ë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.  
        - ì—¬ëŸ¬ ëª…ì˜ ëŒë³´ë¯¸ë¥¼ ì†Œê°œí•  ë•Œë„ ìœ„ ì–‘ì‹ì„ ëŒë³´ë¯¸ë§ˆë‹¤ ë™ì¼í•˜ê²Œ ì ìš©í•©ë‹ˆë‹¤.
        - ë¬¸ë‹¨ë³„ ë“¤ì—¬ì“°ê¸° ë„ì–´ì“°ê¸°ë¥¼ ì ê·¹ ì‚¬ìš©í•´ì„œ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.
            """



    try:
        response = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë”°ëœ»í•œ ë§ˆìŒì„ ê°€ì§„ ìœ¡ì•„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ì¶”ì²œ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
# ğŸ“¦ Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
class TimeSlot(BaseModel):
    start: int
    end: int

class CaregiverConditionUpdate(BaseModel):
    email: str
    available_days: List[str]
    available_times: List[TimeSlot]
    special_child: bool
    age_min: float
    age_max: float

@app.post("/caregiver/update-conditions")
async def update_caregiver_conditions(data: CaregiverConditionUpdate, db: Session = Depends(get_db)):
    # 1. ì´ë©”ì¼ë¡œ ìœ ì € ì¡°íšŒ
    print("ğŸ“¨ ë°›ì€ JSON ë°ì´í„°:\n", json.dumps(data.dict(), indent=2, ensure_ascii=False))
    user = db.query(User).filter(User.email == data.email).first()
    if not user:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì´ë©”ì¼ì˜ ì‚¬ìš©ìê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # 2. ìœ ì €ê°€ ëŒë³´ë¯¸ì¸ì§€ í™•ì¸
    caregiver = db.query(Caregiver).filter(Caregiver.user_id == user.id).first()
    if not caregiver:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì‚¬ìš©ìëŠ” ëŒë³´ë¯¸ê°€ ì•„ë‹™ë‹ˆë‹¤.")

    # 3. ì¡°ê±´ ì—…ë°ì´íŠ¸
    caregiver.available_days = json.dumps(data.available_days, ensure_ascii=False)
    caregiver.available_times = json.dumps([slot.dict() for slot in data.available_times], ensure_ascii=False)
    caregiver.special_child = data.special_child
    caregiver.age_min = data.age_min
    caregiver.age_max = data.age_max

    db.commit()

    return {"message": "ëŒë³´ë¯¸ ì¡°ê±´ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.post("/caregiver/ask/")
def ask_question(req: QueryRequest):
    try:
        #  ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_db.similarity_search(req.prompt, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        #  GPT ì‘ë‹µ ìƒì„± (RAG + ë‹¤ìŒ ì§ˆë¬¸ ìœ ë„)
        prompt = f"""
            ë‹¹ì‹ ì€ 'ëŒë³´ë¯¸ ì„±í–¥ íŒŒì•… ì±—ë´‡' ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° ì‚¬ìš©ìëŠ” ì•„ì´ëŒë³´ë¯¸ë¡œ ì§€ì›í•œ ì‚¬ëŒì´ë©°, ëŒë´„ í˜„ì¥ì—ì„œì˜ ì„±í–¥ê³¼ ìœ„ê¸° ëŒ€ì²˜ëŠ¥ë ¥, ë¶€ëª¨ì™€ì˜ ì†Œí†µ ë°©ì‹, ê°ì • ì¡°ì ˆ ëŠ¥ë ¥ ë“±ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ì´ 15ê°œì˜ **ìƒí™©ê·¹ ê¸°ë°˜ ì§ˆë¬¸**ì„ ìˆœì°¨ì ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.

            [ëª©ì ]

            - ì‚¬ìš©ìì˜ ëŒë´„ ì„±í–¥ì„ íŒŒì•…í•˜ì—¬ ì´í›„ ëŒë´„ ë§¤ì¹­ì— í™œìš©
            - ê³µê°ë ¥, ì±…ì„ê°, ë¬¸ì œ í•´ê²°ë ¥, ì •ì„œì  ì•ˆì •ì„±, ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ ë“±ì˜ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì§‘
            
            [ì„±í–¥]
            
            "parenting_style_vector": [
                "êµìœ¡ ì¤‘ì‹¬", "ì •ì„œ ì¼€ì–´ ì¤‘ì‹¬", "ììœ¨ì„± ì¤‘ì‹¬", "í›ˆìœ¡ ì¤‘ì‹¬",
                "ë†€ì´ ì¤‘ì‹¬", "ì•ˆì „/ë³´í˜¸ ì¤‘ì‹¬", "ì• ì°© ì¤‘ì‹¬", "ì‹ ì²´ í™œë™ ì¤‘ì‹¬"
            ],
            "personality_traits_vector": [
                "ì™¸í–¥ì ", "ë‚´í–¥ì ", "ê°ì„±í˜•", "ì´ì„±í˜•", "ìœµí†µí˜•", "ì›ì¹™í˜•",
                "ê¼¼ê¼¼í˜•", "ììœ í˜•", "ìœ ë¨¸í˜•", "ì¹¨ì°©í˜•"
            ],
            "communication_style_vector": [
                "ì„¤ëª… ì¤‘ì‹¬", "ì§ê´€ ì¤‘ì‹¬", "ëŒ€í™”í˜•", "ë¹„ì–¸ì–´í˜•", "ì§€ì‹œí˜•"
            ],
            "caregiving_attitude_vector": [
                "ì¸ë‚´ì‹¬ ìˆëŠ”", "ì ê·¹ì ì¸", "ì‹ ë¢° ì¤‘ì‹¬", "ê°œì…í˜•", "ê´€ì°°í˜•", "ë…ë¦½ ìœ ë„í˜•"
            ],
            "handling_situations_vector": [
                "ê°ˆë“± ì¤‘ì¬í˜•", "ëŒë°œ ìƒí™© ëŒ€ì‘í˜•", "ê³„íší˜•", "ìœ ì—° ëŒ€ì‘í˜•"
            ],
            "empathy_traits_vector": [
                "ê°ì • ë¯¼ê°í˜•", "ê³µê° ìš°ì„ í˜•", "ë¬´ë˜í•œ í˜•", "ê°ì • í‘œí˜„í˜•"
            ],
            "trust_time_vector": [
                "ì‹œê°„ ì—„ìˆ˜í˜•", "ìœµí†µì„± ìˆëŠ”", "ì‹ ë¢° ìš°ì„ í˜•"
            ]

            [ì§ˆë¬¸ ë°©ì‹]

            - ì§ˆë¬¸ì€ ì‹¤ì œ ì•„ì´ëŒë´„ í˜„ì¥ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìƒí™©ì„ ê°€ì •í•œ **ì—­í• ê·¹ í˜•ì‹**ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
            - ì§ˆë¬¸ì€ í•˜ë‚˜ì”© ì œì‹œë˜ë©°, ì‚¬ìš©ìì˜ ì‘ë‹µ í›„ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
            - ê° ìƒí™©ì€ â€œâ—‹â—‹í•œ ìƒí™©ì—ì„œ ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”?â€ ë˜ëŠ” â€œì´ëŸ´ ë•Œ ì–´ë–¤ ì‹ìœ¼ë¡œ ëŒ€ì‘í•˜ì‹œê² ì–´ìš”?â€ í˜•ì‹ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë¬»ìŠµë‹ˆë‹¤.
            - ëª¨ë“  ì§ˆë¬¸ì€ ë”°ëœ»í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” ë§íˆ¬ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
            - ì‚¬ìš©ì ë°˜ì‘ì„ í†µí•´ ì •ì„±ì ìœ¼ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

            [ì˜ˆì‹œ ì§ˆë¬¸ë“¤]

            1. â€œì•„ì´ê°€ ë°¥ì„ ë¨¹ê¸° ì‹«ë‹¤ê³  ìš¸ë©´ì„œ ë„ë§ë‹¤ë…€ìš”. ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”?â€
            2. â€œë¶€ëª¨ë‹˜ì´ ê°‘ìê¸° ì™¸ì¶œí•˜ì…”ì•¼ í•œë‹¤ë©° ì˜¤ëŠ˜ì€ ë°¤ 10ì‹œê¹Œì§€ ì•„ì´ë¥¼ ë´ì¤„ ìˆ˜ ìˆê² ëƒê³  ìš”ì²­í•˜ì„¸ìš”. í‰ì†Œë³´ë‹¤ 2ì‹œê°„ ëŠ¦ëŠ” ì‹œê°„ì´ì§€ë§Œ ì¶”ê°€ ìš”ì²­ì€ ì²˜ìŒì´ì—ìš”. ì–´ë–»ê²Œ ë°˜ì‘í•˜ì‹œê² ì–´ìš”?â€
            3. â€œì•„ì´ë¥¼ ëŒë³´ëŠ” ì¤‘ ì•„ì´ê°€ ê°‘ìê¸° ì—´ì´ ë‚˜ê¸° ì‹œì‘í–ˆëŠ”ë°, ë¶€ëª¨ë‹˜ì€ ì—°ë½ì´ ë‹¿ì§€ ì•Šì•„ìš”. ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì‹œê² ì–´ìš”?â€
            4. â€œë¶€ëª¨ë‹˜ì´ â€˜ìš°ë¦¬ ì•„ì´ëŠ” ê¹Œë‹¤ë¡œìš´ í¸ì´ë¼ í˜ë“œì‹¤ ê±°ì˜ˆìš”â€™ë¼ê³  ë§í–ˆì„ ë•Œ, ë­ë¼ê³  ë‹µí•˜ì‹œê² ì–´ìš”?â€

            [ì£¼ì˜ ì‚¬í•­]

            - ëŒë³´ë¯¸ë¥¼ í‰ê°€í•˜ê±°ë‚˜ ì‹¬ì‚¬í•˜ëŠ” ì–´íˆ¬ëŠ” ì§€ì–‘í•˜ê³ , ëŒë³´ë¯¸ê°€ **í¸í•˜ê²Œ ìì‹ ì˜ ìŠ¤íƒ€ì¼ì„ í‘œí˜„í•  ìˆ˜ ìˆë„ë¡** ìœ ë„í•©ë‹ˆë‹¤.
            - ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ ì‹ ë¢°ë¥¼ í˜•ì„±í•˜ë©°, ë°˜ì‘ì„ ìœ ë„í•©ë‹ˆë‹¤.
            - ì‚¬ìš©ìì˜ ë‹µë³€ì— ê³µê°í•˜ê±°ë‚˜ ì¸ì •í•˜ëŠ” ë©˜íŠ¸ë¥¼ ê°„ë‹¨íˆ ì²¨ê°€í•œ í›„ ë‹¤ìŒ ì§ˆë¬¸ì„ ì œì‹œí•´ë„ ì¢‹ìŠµë‹ˆë‹¤.
            [ì°¸ê³  ì •ë³´]
            {context}

            [ì§ˆë¬¸]
            {req.prompt}

            [ë‹µë³€]
            """
        
        gpt_result = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì„¬ì„¸í•˜ê³  ë”°ëœ»í•œ ìœ¡ì•„ ìƒë‹´ì‚¬ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        answer = gpt_result.choices[0].message.content.strip()
        return {"answer": answer}

    except Exception as e:
        logger.error(f"/ask/ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")

def calculate_review_weights(review: Review) -> float:
    """ë¦¬ë·°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    # 1. ì‹œê°„ ê°€ì¤‘ì¹˜ (ìµœê·¼ ë¦¬ë·°ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
    time_weight = 1.0
    days_old = (datetime.utcnow() - review.timestamp).days
    time_weight = max(0.5, 1.0 - (days_old / 365))  # 1ë…„ ì´ìƒ ì§€ë‚œ ë¦¬ë·°ëŠ” ìµœì†Œ 0.5 ê°€ì¤‘ì¹˜

    # 2. ê¸¸ì´ ê°€ì¤‘ì¹˜ (ê¸´ ë¦¬ë·°ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
    length_weight = min(1.0, len(review.content) / 500)  # 500ì ì´ìƒì€ ìµœëŒ€ ê°€ì¤‘ì¹˜

    # 3. êµ¬ì²´ì„± ê°€ì¤‘ì¹˜ (êµ¬ì²´ì ì¸ ë‚´ìš©ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
    # ë¬¸ì¥ ìˆ˜ì™€ íŠ¹ì • í‚¤ì›Œë“œì˜ ì¶œí˜„ ë¹ˆë„ë¡œ ê³„ì‚°
    sentences = review.content.split('.')
    keyword_count = sum(1 for s in sentences if any(kw in s.lower() for kw in 
        ['ë•Œ', 'ê²½ìš°', 'ìƒí™©', 'ì˜ˆë¥¼', 'êµ¬ì²´ì ìœ¼ë¡œ', 'íŠ¹íˆ', 'ìì„¸íˆ']))
    specificity_weight = min(1.0, keyword_count / 3)  # 3ê°œ ì´ìƒ í‚¤ì›Œë“œë©´ ìµœëŒ€ ê°€ì¤‘ì¹˜

    # ìµœì¢… ê°€ì¤‘ì¹˜ ê³„ì‚° (ê° ê°€ì¤‘ì¹˜ì˜ í‰ê· )
    final_weight = (time_weight + length_weight + specificity_weight) / 3
    return final_weight

def generate_review_vectors(review_content: str) -> Dict[str, List[float]]:
    """ë¦¬ë·° ë‚´ìš©ì„ ì„±í–¥ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
    prompt = f"""
        ë‹¤ìŒì€ ëŒë³´ë¯¸ì— ëŒ€í•œ ë¦¬ë·° ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë¦¬ë·°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëŒë³´ë¯¸ì˜ ì„±í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
        ë¶„ì„ì€ ë‹¤ìŒ 7ê°œ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        1. ì–‘ìœ¡ ìŠ¤íƒ€ì¼ (êµìœ¡, ì •ì„œ, ììœ¨ì„±, í›ˆìœ¡, ë†€ì´, ì•ˆì „, ì• ì°©, ì‹ ì²´í™œë™)
        2. ì„±ê²© íŠ¹ì„± (ì™¸í–¥ì„±, ë‚´í–¥ì„±, ê°ì„±, ì´ì„±, ìœµí†µì„±, ì›ì¹™ì„±, ê¼¼ê¼¼í•¨, ììœ ë¡œì›€, ìœ ë¨¸, ì¹¨ì°©í•¨)
        3. ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼ (ì„¤ëª…, ì§ê´€, ëŒ€í™”, ë¹„ì–¸ì–´, ì§€ì‹œ)
        4. ëŒë´„ íƒœë„ (ì¸ë‚´ì‹¬, ì ê·¹ì„±, ì‹ ë¢°, ê°œì…, ê´€ì°°, ë…ë¦½)
        5. ìƒí™© ëŒ€ì²˜ (ê°ˆë“±, ëŒë°œìƒí™©, ê³„íš, ìœ ì—°ì„±)
        6. ê³µê° íŠ¹ì„± (ê°ì •ë¯¼ê°ì„±, ê³µê°, ë¬´ë˜í•¨, í‘œí˜„)
        7. ì‹ ë¢°/ì‹œê°„ (ì‹œê°„ì—„ìˆ˜, ìœµí†µì„±, ì‹ ë¢°)

        ë¦¬ë·° ë‚´ìš©:
        {review_content}

        ìš”ì•½:
    """

    try:
        response = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒë³´ë¯¸ì˜ ì„±í–¥ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        summary = response.choices[0].message.content.strip()
        return generate_vectors_from_summary(summary)
    except Exception as e:
        print(f"ë¦¬ë·° ë²¡í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {}

def update_caregiver_vectors_from_review(caregiver: Caregiver, review_vectors: Dict[str, List[float]], weight: float):
    """ë¦¬ë·° ë²¡í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒë³´ë¯¸ì˜ ì„±í–¥ ë²¡í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜ (ì§€ìˆ˜ ê°ì‡  ì ìš©)"""
    vector_fields = [
        "parenting_style_vector",
        "personality_traits_vector",
        "communication_style_vector",
        "caregiving_attitude_vector",
        "handling_situations_vector",
        "empathy_traits_vector",
        "trust_time_vector"
    ]

    def exponential_update_with_boost_floor(current, target, weight, boost=1.5):
        """
        target: ë¦¬ë·°ì—ì„œ ì¶”ì¶œëœ ì„±í–¥ (0~1 ì˜ˆìƒ)
        current: í˜„ì¬ ëŒë³´ë¯¸ì˜ ì„±í–¥ ì ìˆ˜
        weight: ë¦¬ë·° ì‹ ë¢°ë„ (0~1)
        boost: ê°•í•˜ê²Œ ë°˜ì˜ë˜ë„ë¡ í•˜ëŠ” ê°•í™” ê³„ìˆ˜ (ê¸°ë³¸ 1.5)
        """
        diff = target - current
        adjustment = diff * weight * (1 - abs(current)) * boost
        updated = current + adjustment
        return min(1.0, max(0.0, updated))  # 0~1ë¡œ ì œí•œ
  

    for field in vector_fields:
        current_vector = json.loads(getattr(caregiver, field) or "[]")
        review_vector = review_vectors.get(field, [0.0] * len(current_vector))
        
        updated_vector = [
            exponential_update_with_boost_floor(c, r,weight) for c, r in zip(current_vector, review_vector)
        ]
        
        setattr(caregiver, field, json.dumps(updated_vector))
        
@app.post("/reviews/", response_model=ReviewRead)
def create_review(req: ReviewCreate, db: Session = Depends(get_db)):
    # 1. ë¦¬ë·° ìƒì„±
    review = Review(
        caregiver_id=req.caregiver_id,
        parent_name=req.parent_name,
        content=req.content
    )
    db.add(review)
    db.commit()
    db.refresh(review)

    # 2. ëŒë³´ë¯¸ ì¡°íšŒ
    caregiver = db.query(Caregiver).filter(Caregiver.id == req.caregiver_id).first()
    if not caregiver:
        raise HTTPException(status_code=404, detail="ëŒë³´ë¯¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 3. ë¦¬ë·° ë²¡í„° ìƒì„±
    review_vectors = generate_review_vectors(req.content)
    if not review_vectors:
        return review

    # 4. ë¦¬ë·° ê°€ì¤‘ì¹˜ ê³„ì‚°
    weight = calculate_review_weights(review)

    # 5. ëŒë³´ë¯¸ ë²¡í„° ì—…ë°ì´íŠ¸
    update_caregiver_vectors_from_review(caregiver, review_vectors, weight)
    db.commit()

    return review

@app.get("/reviews/{caregiver_id}", response_model=List[ReviewRead])
def list_reviews(caregiver_id: int, db: Session = Depends(get_db)):
    return db.query(Review).filter(Review.caregiver_id == caregiver_id).all()

@app.post("/recommend/ask/")
def ask_question(req: QueryRequest):
    try:
        # ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_db.similarity_search(req.prompt, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        # ğŸ§  GPT ì‘ë‹µ ìƒì„± (RAG + ë‹¤ìŒ ì§ˆë¬¸ ìœ ë„)
        prompt = f"""
            ë„ˆëŠ” ì‚¬ìš©ìì™€ ê°ì •ì ìœ¼ë¡œ ì—°ê²°ë˜ë©°, ìœ¡ì•„ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì£¼ì œì—ì„œ ì„±í–¥ì„ íŒŒì•…í•˜ê³  ì ì ˆí•œ ëŒë³´ë¯¸ ë§¤ì¹­ì„ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼.
            ì•„ë˜ ì°¸ê³  ì •ë³´ë¥¼ í™œìš©í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë”°ëœ»í•˜ê²Œ ë‹µë³€í•´ì¤˜. ì•„ì´ì˜ ì„±í–¥ì„ ì–˜ê¸°í•˜ë©´ ê·¸ì— ì í•©í•œ ëŒë³´ë¯¸ë¥¼ ë§¤ì¹­í•´ì£¼ëŠ” ê±°ì•¼. 
            ê·¸ë¦¬ê³  ì„±í–¥ì„ ì˜ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ í•­ìƒ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì„ ì´ì–´ê°€ë„ë¡ í•´ì¤˜.
            ë¬¸ë§¥ì— ë”°ë¼ ì‚¬ìš©ìê°€ í˜ë“¤ì–´í•˜ê±°ë‚˜ ì‹¬ë¦¬ì ìœ¼ë¡œ ë¶ˆì•ˆì •í•˜ë©´ ìœ„ë¡œí•´ì¤˜. í•˜ì§€ë§Œ ì œì¼ ìš°ì„ í•´ì•¼í•  ê²ƒì€ ëŒë³´ë¯¸ ë§¤ì¹­ì„ ìœ„í•œ ì„±í–¥ íŒŒì•…ì´ì•¼.
            ê²°ê³¼ì ìœ¼ë¡œ ë„ˆëŠ” ëŒë³´ë¯¸ ë§¤ì¹­ì„ ìœ„í•´ ì¡´ì¬í•˜ëŠ”ê±°ì•¼. ëŒë³´ë¯¸ ë§¤ì¹­ì´ ìµœìš°ì„ ì´ì•¼. ëŒë³´ë¯¸=ë³´ëª¨=ë³´í˜¸ì
            [ì°¸ê³  ì •ë³´]
            {context}

            [ì§ˆë¬¸]
            {req.prompt}

            [ë‹µë³€]
            """
        
        gpt_result = client.chat.completions.create(
            model=chat_model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì„¬ì„¸í•˜ê³  ë”°ëœ»í•œ ìœ¡ì•„ ìƒë‹´ì‚¬ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        answer = gpt_result.choices[0].message.content.strip()
        return {"answer": answer}

    except Exception as e:
        logger.error(f"/ask/ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")