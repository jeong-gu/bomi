import os
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.documents import Document

def prepare_chroma_db_all(data_dir: str, persist_dir: str):
    """
    ì „ì²´ í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë²¡í„° DBë¡œ í†µí•© ì €ì¥
    """
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    all_documents = []

    for root, _, files in os.walk(data_dir):
        for file in files:
            if not file.endswith(".txt"):
                continue
            file_path = os.path.join(root, file)
            try:
                loader = TextLoader(file_path, encoding="utf-8")
                text = loader.load()[0].page_content
                doc = Document(page_content=text, metadata={"source": file_path})
                all_documents.append(doc)
                print(f"âœ… ë¡œë“œ ì™„ë£Œ: {file_path}")
            except Exception as e:
                print(f"âŒ ì—ëŸ¬: {file_path} - {str(e)}")

    # í†µí•© ë²¡í„° DB ì €ì¥
    vector_db = Chroma.from_documents(
        documents=all_documents,
        embedding=embedding_model,
        persist_directory=persist_dir
    )
    print(f"ğŸ‰ í†µí•© ì €ì¥ ì™„ë£Œ! ì´ {len(all_documents)}ê°œ ë¬¸ì„œ")

if __name__ == "__main__":
    data_dir = "./data"               # ì˜ˆì‹œ: 'data/' ë””ë ‰í† ë¦¬ ì „ì²´ íƒìƒ‰
    persist_dir = "./vectorDB"    # í•˜ë‚˜ì˜ DBë¡œ ì €ì¥
    prepare_chroma_db_all(data_dir, persist_dir)
